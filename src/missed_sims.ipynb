{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ced2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = os.getcwd()\n",
    "sample_folder = '\\\\res'\n",
    "res_folder = '\\\\res\\\\trn'\n",
    "os.chdir(directory+res_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b01918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3699\n",
      "1233\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "test = os.listdir()\n",
    "avl_labels_og = [] # avaliable labels in the \n",
    "for i in test:\n",
    "    if '_temp_flow' in i:\n",
    "        prefix = i[:-14]\n",
    "    elif '_control_signal' in i:\n",
    "        prefix = i[:-19]\n",
    "    elif '_energy' in i:\n",
    "        prefix = i[:-11]\n",
    "    else:\n",
    "        continue\n",
    "    avl_labels_og.append(prefix)\n",
    "print(len(avl_labels_og))        \n",
    "avl_labels_og = np.array(avl_labels_og)\n",
    "avl_labels_og = np.unique(avl_labels_og)\n",
    "print(len(avl_labels_og))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f135f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# compare with current_list and flag the ones that have been completely missed\n",
    "# Add these values to the repeat dataframe\n",
    "# To check with indiecs of current list, labels have to be converted to numeric values, especially labels with _cp\n",
    "if len(avl_labels_og)==0:\n",
    "    starting_label=0\n",
    "else:\n",
    "    existing_res = pd.read_csv('..\\\\sim_results.csv')\n",
    "    starting_label = existing_res.index[-1]+1\n",
    "    \n",
    "repeat = pd.DataFrame()\n",
    "current = pd.read_csv('..\\\\current_list.csv', header=0, index_col=0)\n",
    "#current = pd.read_csv('..\\\\redo.csv', header=0, index_col=0)\n",
    "current_index = [str(i+starting_label) for i in current.index]\n",
    "\n",
    "avl_labels = np.array([''.join(filter(str.isdigit, s)) for s in avl_labels_og])\n",
    "\n",
    "missing = list(set(current_index)-set(avl_labels))\n",
    "print(missing)\n",
    "\n",
    "for i in missing:\n",
    "    repeat = repeat.append(current.loc[int(i)-starting_label])\n",
    "repeat.head()\n",
    "\n",
    "corrected_index = [i+starting_label for i in repeat.index]\n",
    "repeat.index = corrected_index\n",
    "\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2450aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if redo.cs is read, the labels can be converted to string. But the postfix _cp has to \n",
    "# added to the ones with design_case cp\n",
    "# then the missing values labels are removed from the redo labels list\n",
    "read_file = '..\\\\redo.csv'\n",
    "inp = pd.read_csv(read_file, header=0,index_col=0)\n",
    "\n",
    "if 'redo' in read_file:\n",
    "    redo_labels = []\n",
    "    for i in inp.index:\n",
    "        if 'cp' in inp['design_case'][i]:\n",
    "            redo_labels.append(str(i)+'_cp')\n",
    "        else:\n",
    "            redo_labels.append(str(i))\n",
    "        avl_labels_og = list(set(redo_labels)-set(missing))\n",
    "len(avl_labels_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bc3b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f58f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023 len = 77666\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 57 fields in line 26581, saw 67\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b1296db36a5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print(i+'_control_signal.txt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_control_signal.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_temp_flow.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_energy.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m87601\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m87601\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m87601\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 57 fields in line 26581, saw 67\n"
     ]
    }
   ],
   "source": [
    "# check length of all files and flag the onces that are incomplete\n",
    "\n",
    "read_file = 'list_of_inputs.csv'\n",
    "#read_file = '..\\\\redo.csv'\n",
    "inp = pd.read_csv(read_file, header=0,index_col=0)\n",
    "\n",
    "for i in avl_labels_og:\n",
    "    #print(i+'_control_signal.txt')\n",
    "    df = pd.read_csv(i+'_control_signal.txt', delimiter=',',index_col=0) \n",
    "    df2 = pd.read_csv(i+'_temp_flow.txt', delimiter=',',index_col=0) \n",
    "    df3 = pd.read_csv(i+'_energy.txt', delimiter=',',index_col=0) \n",
    "    if (len(df) <87601 or len(df2) <87601 or len(df3) <87601) :\n",
    "        print(i + ' len = '+str(len(df)))\n",
    "        j = ''.join([char for char in i if char.isdigit()])\n",
    "        repeat = repeat.append(inp.loc[int(j)])\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3829646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023 len = 77666\n",
      "1108 len = 84943\n",
      "1110 len = 76635\n",
      "1111 len = 77575\n",
      "1112 len = 29411\n",
      "1116_cp len = 24499\n",
      "1117_cp len = 18089\n"
     ]
    }
   ],
   "source": [
    "# create repeat dataframe from current_list\n",
    "avl_labels = np.array([''.join(filter(str.isdigit, s)) for s in avl_labels_og])\n",
    "labels_all = list(range(861,1232))\n",
    "labels_all = [str(i) for i in labels_all]\n",
    "labels = [i for i in labels_all if i in avl_labels]\n",
    "og_labels = []\n",
    "for alo in avl_labels_og:\n",
    "     if any(alo.startswith(l) for l in labels):\n",
    "        og_labels.append(alo)\n",
    "        \n",
    "read_file = '..\\\\current_list.csv'\n",
    "repeat2 = pd.DataFrame()\n",
    "inp = pd.read_csv(read_file, header=0,index_col=0)\n",
    "for i in og_labels:\n",
    "    #print(i+'_control_signal.txt')\n",
    "    df = pd.read_csv(i+'_control_signal.txt', delimiter=',',index_col=0) \n",
    "    df2 = pd.read_csv(i+'_temp_flow.txt', delimiter=',',index_col=0) \n",
    "    df3 = pd.read_csv(i+'_energy.txt', delimiter=',',index_col=0) \n",
    "    if (len(df) <87601 or len(df2) <87601 or len(df3) <87601) :\n",
    "        print(i + ' len = '+str(len(df)))\n",
    "        j = ''.join([char for char in i if char.isdigit()])\n",
    "        repeat2 = repeat2.append(inp.loc[int(j)-starting_label])\n",
    "\n",
    "repeat2.index = [i-starting_label for i in repeat2.index]\n",
    "repeat = pd.concat([repeat,repeat2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f29ec906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create repeat dataframe from redo list\n",
    "redo = pd.read_csv('..\\\\redo.csv',index_col=0)\n",
    "redo_index = redo.index\n",
    "labels = []\n",
    "for i in redo.index:\n",
    "    if redo['design_case'].loc[i]=='cp_PV':\n",
    "        labels.append(str(i)+'_cp')\n",
    "    else:\n",
    "        labels.append(str(i))\n",
    "\n",
    "repeat2 = pd.DataFrame()\n",
    "for i in labels:\n",
    "    df = pd.read_csv(i+'_control_signal.txt', delimiter=',',index_col=0) \n",
    "    df2 = pd.read_csv(i+'_temp_flow.txt', delimiter=',',index_col=0) \n",
    "    df3 = pd.read_csv(i+'_energy.txt', delimiter=',',index_col=0) \n",
    "    if (len(df) <87601 or len(df2) <87601 or len(df3) <87601) :\n",
    "        print(i + ' len = '+str(len(df)))\n",
    "        j = ''.join([char for char in i if char.isdigit()])\n",
    "        repeat2 = repeat2.append(redo.loc[int(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ca0e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df06a534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trial of difference using sets\n",
    "\n",
    "a = ['1','2','3','4','5_cp','6_cp']\n",
    "a2 = np.array([''.join(filter(str.isdigit, s)) for s in a])\n",
    "b = ['1','2','3','4','5','7']\n",
    "\n",
    "list(set(b)-set(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18f34a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat.to_csv('..\\\\redo.csv',index_label='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "908858c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['482',\n",
       " '729',\n",
       " '733',\n",
       " '766',\n",
       " '791',\n",
       " '794',\n",
       " '795',\n",
       " '808',\n",
       " '815',\n",
       " '853',\n",
       " '854',\n",
       " '856']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make labels in the repeat dataframe, to delete the input files from the directories\n",
    "labels = []\n",
    "for i in repeat.index:\n",
    "    if repeat.loc[i]['design_case']== 'cp_PV':\n",
    "        labels.append(str(i)+'_cp')\n",
    "    else:\n",
    "        labels.append(str(i))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a07496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the input files that correspond with repeat labels\n",
    "house_folder = '..\\\\..\\\\house_and_backup'\n",
    "backup_folder = '..\\\\..\\\\house_and_backup\\\\backup'\n",
    "\n",
    "hfiles = os.listdir(house_folder)\n",
    "bfiles = os.listdir(backup_folder)\n",
    "\n",
    "# Iterate through the files and delete files with numbers from the list\n",
    "for file in hfiles:\n",
    "    for number in labels:\n",
    "        if number in file:\n",
    "            file_path = os.path.join(house_folder, file)\n",
    "            os.remove(file_path)\n",
    "\n",
    "for file in bfiles:\n",
    "    for number in labels:\n",
    "        if number in file:\n",
    "            file_path = os.path.join(backup_folder, file)\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e8b51cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length of file from missed sims list and flag the onces that are incomplete\n",
    "os.chdir(directory+res_folder)\n",
    "import pandas as pd\n",
    "repeat = pd.DataFrame()\n",
    "inp = pd.read_csv('..\\\\redo.csv', header=0, index_col=0)\n",
    "for i in inp.index:\n",
    "    df = pd.read_csv(str(i)+'_control_signal.txt', delimiter=',',index_col=0) \n",
    "    if len(df) <87601 :\n",
    "        print(str(i) + ' len = '+str(len(df)))\n",
    "        #j = ''.join([char for char in i if char.isdigit()])\n",
    "        repeat = repeat.append(inp.loc[int(i)])\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1ea16c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lhs_sample_1.csv',\n",
       " 'morris_sample_batt1.csv',\n",
       " 'morris_sample_cp.csv',\n",
       " 'morris_sample_cp2.csv',\n",
       " 'morris_sample_cp3.csv',\n",
       " 'morris_sample_pvt.csv',\n",
       " 'morris_sample_pvt2.csv',\n",
       " 'morris_sample_pvt3.csv',\n",
       " 'morris_sample_pvt4.csv',\n",
       " 'morris_sample_st.csv',\n",
       " 'morris_sample_st2.csv',\n",
       " 'morris_sample_st3.csv',\n",
       " 'morris_sample_st4.csv']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir('..')\n",
    "sample_files = []\n",
    "for file in all_files:\n",
    "    if 'sample' in file:\n",
    "        sample_files.append(file)\n",
    "sample_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8deaf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list = [356]\n",
    "df2 = dfnew.iloc[dfnew.index.isin(slice_list)]\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
